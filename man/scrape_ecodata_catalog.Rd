% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scrape_ecodata_catalog.R
\name{scrape_ecodata_catalog}
\alias{scrape_ecodata_catalog}
\title{Scrape ecodata catalog page}
\usage{
scrape_ecodata_catalog(url, FieldList)
}
\arguments{
\item{url}{The url of the catalog page to be scraped}

\item{FieldList}{A character vector of fields to be scraped; must match case and spelling}
}
\value{
a dataframe with variables from the FieldList and values from the catalog webpage. Columns:
\itemize{
\item{\code{Indicator}, name of the indicator extracted from catalog page title}
\item{\code{Source}, URL of the catalog page}
\item{\code{Varname}, variable names corresponding to matches from the FieldList}
\item{\code{Value}, text for each variable name from the catalog page}
}
}
\description{
Pulls selected fields, paragraphs, and images from the NOAA-EDAB Indicator Catalog website
and returns a dataframe of the .
Code had to be tailored to this website because not all fields come under standard headers.
}
\examples{
 url <- "https://noaa-edab.github.io/catalog/trans_dates.html"
 FieldList <- c("Description", "Introduction", "Key Results",
                 "Spatial scale", "Temporal scale", "Implications",
                 "Point of contact", "ecodata name", "tech-doc link")
 scrape_ecodata_catalog(url, FieldList)

}
